{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8e3c99",
   "metadata": {},
   "source": [
    "# Recipe Generator Using Pretrained AI\n",
    "This notebook generates recipes based on user-provided ingredients using a pretrained AI model (e.g., GPT-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5022e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edrikisaian/Documents/Advanced_AI/AdvancedAI_IndividualProject/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import os\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7fabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881cab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d02a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a17f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal (MPS) for inference\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"Using Metal (MPS) for inference\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Using CPU for inference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98799ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
    "    model.to(device)\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd05722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_ingredients():\n",
    "    users_ingredients = []\n",
    "    print(\"Enter the ingredients you have (type 'end' to finish):\")\n",
    "    while True:\n",
    "        user_input = input(\"Ingredient: \").strip().lower()\n",
    "        if user_input == 'end':\n",
    "            break\n",
    "        if user_input:\n",
    "            users_ingredients.append(user_input)\n",
    "    return users_ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5297004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(ingredients, model, tokenizer, max_loops=5):\n",
    "    prompt = (\n",
    "        f\"Given these ingredients: {', '.join(ingredients)}, suggest 1–3 recipes I can make. \"\n",
    "        \"For each recipe, provide a short and structured list of steps. Use bullet points. \"\n",
    "        \"Keep the instructions brief, clear, and limited to essential steps only. Do not add extra explanation or repetition.\"\n",
    "    )\n",
    "\n",
    "    generated_text = prompt\n",
    "    for i in range(max_loops):\n",
    "        inputs = tokenizer(generated_text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            no_repeat_ngram_size=3,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        if output_text == generated_text:\n",
    "            break\n",
    "        generated_text = output_text\n",
    "        if \"enjoy your meal\" in output_text.lower() or \"bon appétit\" in output_text.lower():\n",
    "            break\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459e662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    clear_memory()\n",
    "\n",
    "    print(\"Welcome to the AI Recipe Generator!\")\n",
    "\n",
    "    model, tokenizer = load_model()\n",
    "\n",
    "    ingredients = get_users_ingredients()\n",
    "    if not ingredients:\n",
    "        print(\"No ingredients provided. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nGenerating recipe suggestions...\\n\")\n",
    "    try:\n",
    "        recipe = generate_recipe(ingredients, model, tokenizer)\n",
    "        print(\"Here are the recipe suggestions:\\n\")\n",
    "        print(recipe)\n",
    "    except Exception as e:\n",
    "        print(\"Error generating recipe:\\n\")\n",
    "        print(e)\n",
    "        print(\"\\nSorry, I couldn't generate a recipe. Please try again.\")\n",
    "    \n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348868d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the AI Recipe Generator!\n",
      "Enter the ingredients you have (type 'end' to finish):\n",
      "\n",
      "Generating recipe suggestions...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venv",
   "language": "python",
   "name": "my-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
